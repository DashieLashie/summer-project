{
 "cells": [
  {
   "cell_type": "code",
   "id": "f557f182-8581-4b2a-9506-80baadbb2af7",
   "metadata": {
    "id": "f557f182-8581-4b2a-9506-80baadbb2af7"
   },
   "source": [
    "!ln -s /mnt/datasets/stocknet-dataset stocknet"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "l-a6H_BFhw1b",
   "metadata": {
    "collapsed": true,
    "id": "l-a6H_BFhw1b",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "eb91ac34-3614-4973-9077-3a5029a5bbc8",
   "metadata": {
    "id": "eb91ac34-3614-4973-9077-3a5029a5bbc8"
   },
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import re"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2025675a-ba00-4249-861b-856b298c728d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2025675a-ba00-4249-861b-856b298c728d",
    "outputId": "547d72e8-f5e7-41ac-befb-c2146571e0fb"
   },
   "source": [
    "\n",
    "directory = \"/content/stocknet-dataset/price/raw\"\n",
    "\n",
    "stock_data = {}\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        ticker = filename.replace(\".csv\", \"\")\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        df = pd.read_csv(filepath, parse_dates=[\"Date\"])\n",
    "        df.set_index(\"Date\", inplace=True)\n",
    "        stock_data[ticker] = df\n",
    "\n",
    "print(stock_data[\"RDS-B\"].head())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a3f1f862-01cf-4074-885f-5fa5cb2a23ca",
   "metadata": {
    "id": "a3f1f862-01cf-4074-885f-5fa5cb2a23ca"
   },
   "source": [
    "tidy_df = pd.concat(\n",
    "    [df.assign(Ticker=ticker) for ticker, df in stock_data.items()],\n",
    "    axis=0\n",
    ").reset_index()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0e360e0f-dcd8-45c2-8124-372ff5778771",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "0e360e0f-dcd8-45c2-8124-372ff5778771",
    "outputId": "4ebb9cfb-9289-421b-b0dd-2bfb6c293199",
    "scrolled": true
   },
   "source": [
    "tidy_df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "be7895bc-23a5-4d97-8ce2-2d458923429f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "be7895bc-23a5-4d97-8ce2-2d458923429f",
    "outputId": "b5a018c6-569f-4641-8089-47cc6f4eccd5"
   },
   "source": [
    "\n",
    "root_dir = \"/content/stocknet-dataset/tweet/preprocessed\"\n",
    "\n",
    "all_tweets = []\n",
    "\n",
    "for ticker in os.listdir(root_dir):\n",
    "    subfolder = os.path.join(root_dir, ticker)\n",
    "    if os.path.isdir(subfolder):\n",
    "        for file in os.listdir(subfolder):\n",
    "            filepath = os.path.join(subfolder, file)\n",
    "            if os.path.isfile(filepath):\n",
    "                try:\n",
    "                    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "                        try:\n",
    "\n",
    "                            tweet = json.load(f)\n",
    "                            tweets = [tweet]\n",
    "                        except json.JSONDecodeError:\n",
    "\n",
    "                            f.seek(0)\n",
    "                            tweets = [json.loads(line) for line in f if line.strip()]\n",
    "\n",
    "                        for tweet in tweets:\n",
    "                            flat_text = \" \".join(tweet.get(\"text\", []))\n",
    "                            all_tweets.append({\n",
    "                                \"ticker\": ticker,\n",
    "                                \"text\": flat_text,\n",
    "                                \"created_at\": tweet.get(\"created_at\"),\n",
    "                                \"user_id\": tweet.get(\"user_id_str\")\n",
    "                            })\n",
    "                except Exception as e:\n",
    "                    print(f\"Skipping file {filepath} due to error: {e}\")\n",
    "\n",
    "tweet_df = pd.DataFrame(all_tweets)\n",
    "tweet_df[\"created_at\"] = pd.to_datetime(tweet_df[\"created_at\"], errors=\"coerce\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "46dfbe3b-9bca-4a72-a9aa-82fcb7d53808",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 597
    },
    "id": "46dfbe3b-9bca-4a72-a9aa-82fcb7d53808",
    "outputId": "cce458b2-1e04-4926-9da1-54f33adff457"
   },
   "source": [
    "tweet_df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "dfd1f978-5401-4440-81b6-f46839fcfbad",
   "metadata": {
    "id": "dfd1f978-5401-4440-81b6-f46839fcfbad"
   },
   "source": [
    "def clean_text():\n",
    "    char_patterns = re.compile('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+|#[a-zA-Z]+|$[a-zA-Z]+|@[a-zA-Z]+|[,.^_$*%-;!?:]')\n",
    "    for i in range(len(tweet_df[\"text\"])):\n",
    "        tweet_df[\"text\"][i] = char_patterns.sub('', tweet_df[\"text\"][i])\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6imjt8QYj9G6",
   "metadata": {
    "id": "6imjt8QYj9G6"
   },
   "source": [
    "def date_extract(datetime_obj):\n",
    "  return str(datetime_obj.date())[:10]\n",
    "\n",
    "tweet_df['date'] = tweet_df['created_at'].apply(date_extract)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "Kc2gFKEHkX5u",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 597
    },
    "id": "Kc2gFKEHkX5u",
    "outputId": "14bff239-aad0-4f77-e92b-c538d62ccca3"
   },
   "source": [
    "tweet_df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "F9BOCjbPlD3L",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 903
    },
    "id": "F9BOCjbPlD3L",
    "outputId": "7657d205-1032-445f-9814-14d954329e79"
   },
   "source": [
    "clean_text()\n",
    "tweet_df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "rE-3zUz-oVGz",
   "metadata": {
    "id": "rE-3zUz-oVGz"
   },
   "source": [
    "tidy_df.to_parquet('stock_prices.parquet',index=False)\n",
    "tweet_df.to_parquet('stock_tweets.parquet',index=False)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
